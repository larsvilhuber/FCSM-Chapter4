
@misc{iso_iso_nodate,
	title = {{ISO} 25237:2017: {Health} informatics - {Pseudonymization}},
	shorttitle = {{ISO} 25237:2017(en)},
	url = {https://www.iso.org/standard/63553.html},
	abstract = {Health informatics — Pseudonymization},
	language = {en},
	urldate = {2020-03-19},
	journal = {ISO},
	author = {{ISO}}
}

@misc{oecd_oecd_nodate,
	title = {The {OECD} {Glossary} of {Statistical} {Terms}},
	url = {https://stats.oecd.org/glossary/},
	urldate = {2020-03-19},
	author = {{OECD}}
}

@misc{nist_information_technology_laboratory_glossary_nodate,
	title = {Glossary of {Computer} {Security} {Terms}},
	url = {https://csrc.nist.gov/glossary},
	urldate = {2020-03-19},
	author = {{NIST Information Technology Laboratory}}
}

@inproceedings{dwork_calibrating_2006,
	address = {Berlin, Heidelberg},
	title = {Calibrating {Noise} to {Sensitivity} in {Private} {Data} {Analysis}},
	volume = {3876},
	doi = {10.1007/11681878_14},
	urldate = {2020-03-20},
	booktitle = {Theory of {Cryptography}},
	publisher = {Springer Berlin Heidelberg},
	author = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
	year = {2006},
	pages = {265--284}
}

@article{dwork_calibrating_2016,
	title = {Calibrating {Noise} to {Sensitivity} in {Private} {Data} {Analysis}},
	volume = {7},
	doi = {10.29012/jpc.v7i3.405},
	abstract = {We continue a line of research initiated in Dinur and Nissim (2003); Dwork and Nissim (2004); and Blum et al. (2005) on privacy-preserving statistical databases. Consider a trusted server that holds a database of sensitive information. Given a query function \$f\$ mapping databases to reals, the so-called \{{\textbackslash}textbackslashem true answer\} is the result of applying \$f\$ to the database. To protect privacy, the true answer is perturbed by the addition of random noise generated according to a carefully chosen distribution, and this response, the true answer plus noise, is returned to the user. Previous work focused on the case of noisy sums, in which \$f = {\textbackslash}sum\_i g(x\_i)\$, where \$x\_i\$ denotes the \$i\$th row of the database and \$g\$ maps database rows to \$[0,1]\$. We extend the study to general functions \$f\$, proving that privacy can be preserved by calibrating the standard deviation of the noise according to the \{{\textbackslash}textbackslashem sensitivity\} of the function \$f\$. Roughly speaking, this is the amount that any single argument to \$f\$ can change its output. The new analysis shows that for several particular applications substantially less noise is needed than was previously understood to be the case. The first step is a very clean definition of privacy—now known as differential privacy—and measure of its loss. We also provide a set of tools for designing and combining differentially private algorithms, permitting the construction of complex differentially private analytical tools from simple differentially private primitives. Finally, we obtain separation results showing the increased value of interactive statistical release mechanisms over non-interactive ones.},
	number = {3},
	journal = {Journal of Privacy and Confidentiality},
	author = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
	year = {2016}
}

@techreport{freiman_formal_2017,
	title = {Formal {Privacy} and {Synthetic} {Data} for the {American} {Community} {Survey}},
	url = {https://www.census.gov/library/working-papers/2018/adrm/formal-privacy-synthetic-data-acs.html},
	language = {EN-US},
	urldate = {2020-03-20},
	institution = {U.S. Census Bureau},
	author = {Freiman, Michael H. and Lauger, Amy D. and Reiter, Jerome P.},
	year = {2017}
}

@misc{us_code_title_1954,
	title = {Title 13 -- {Census}},
	url = {https://www.govinfo.gov/content/pkg/USCODE-2007-title13/pdf/USCODE-2007-title13.pdf},
	urldate = {2020-03-21},
	author = {{U.S. Code}},
	year = {1954},
	note = {as amended 2007}
}

@misc{us_census_bureau_title_nodate,
	title = {Title 26, {U}.{S}. {Code} - {History} - {U}.{S}. {Census} {Bureau}},
	url = {https://www.census.gov/history/www/reference/privacy_confidentiality/title_26_us_code_1.html},
	abstract = {Body of laws codifying tax laws and the protection of these data.},
	language = {EN-US},
	urldate = {2020-03-21},
	author = {{US Census Bureau}},
	note = {Library Catalog: www.census.gov}
}

@article{dwork_algorithmic_2013,
	title = {The {Algorithmic} {Foundations} of {Differential} {Privacy}},
	volume = {9},
	url = {http://www.nowpublishers.com/articles/foundations-and-trends-in-theoretical-computer-science/TCS-042},
	doi = {10.1561/0400000042},
	language = {en},
	number = {3-4},
	urldate = {2020-03-19},
	journal = {Foundations and Trends® in Theoretical Computer Science},
	author = {Dwork, Cynthia and Roth, Aaron},
	year = {2013}
}

@inproceedings{mcsherry_mechanism_2007,
	address = {Providence, RI, USA},
	title = {Mechanism {Design} via {Differential} {Privacy}},
	isbn = {978-0-7695-3010-9},
	url = {http://ieeexplore.ieee.org/document/4389483/},
	doi = {10.1109/FOCS.2007.66},
	urldate = {2020-03-20},
	booktitle = {48th {Annual} {IEEE} {Symposium} on {Foundations} of {Computer} {Science} ({FOCS}'07)},
	publisher = {IEEE},
	author = {McSherry, Frank and Talwar, Kunal},
	month = oct,
	year = {2007},
	pages = {94--103}
}

@misc{noauthor_about_2016,
	title = {About {Controlled} {Unclassified} {Information} ({CUI})},
	url = {https://www.archives.gov/cui/about},
	abstract = {Controlled Unclassified Information (CUI) is information that requires safeguarding or dissemination controls pursuant to and consistent with applicable law, regulations, and government-wide policies but is not classified under Executive Order 13526 or the Atomic Energy Act, as amended. Executive Order 13556 "Controlled Unclassified Information" (the Order), establishes a program for managing CUI across the Executive branch and designates the National Archives and Records Administration (NARA) as Executive Agent to implement the Order and oversee agency actions to ensure compliance.},
	language = {en},
	urldate = {2020-03-20},
	journal = {National Archives},
	month = aug,
	year = {2016},
	note = {Library Catalog: www.archives.gov}
}

@article{reiter_verification_2009,
	title = {Verification servers: {Enabling} analysts to assess the quality of inferences from public use data},
	volume = {53},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947308004751},
	doi = {10.1016/j.csda.2008.10.006},
	abstract = {To protect confidentiality, statistical agencies typically alter data before releasing them to the public. Ideally, although generally not done, the agency also provides a way for secondary data analysts to assess the quality of inferences obtained with the released data. Quality measures can help secondary data analysts to identify inaccurate conclusions resulting from the disclosure limitation procedures, as well as have confidence in accurate conclusions. We propose a framework for an interactive, web-based system that analysts can query for measures of inferential quality. As we illustrate, agencies seeking to build such systems must consider the additional disclosure risks from releasing quality measures. We suggest some avenues of research on limiting these risks.},
	number = {4},
	journal = {Computational statistics \& data analysis},
	author = {Reiter, Jerome P and Oganian, Anna and Karr, Alan F},
	month = feb,
	year = {2009},
	pages = {1475--1482}
}

@techreport{desai_five_2016,
	type = {Working {Paper}},
	title = {Five {Safes}: designing data access for research},
	url = {http://eprints.uwe.ac.uk/28124},
	abstract = {What is the best way of managing access to sensitive data? This is not a straightforward question, as it involves the interaction of legal, technical, statistical and, above all, human components to produce a solution. This paper introduces a modelling tool designed to simplify and structure such decision-making.},
	language = {en},
	institution = {University of the West of England},
	author = {Desai, Tanvi and Ritchie, Felix and Welpton, Richard},
	year = {2016},
	keywords = {confidentiality, data  management, data access, data management, security  engineering, security engineering, statistical  disclosure control, statistical disclosure control},
	pages = {27}
}

@techreport{us_census_bureau_data_2020,
	type = {mimeo},
	title = {Data {Metrics} for 2020 {Disclosure} {Avoidance}},
	url = {https://www2.census.gov/programs-surveys/decennial/2020/program-management/data-product-planning/disclosure-avoidance-system/2020-03-25-data-metrics-2020-da.pdf},
	urldate = {2020-03-27},
	author = {{U.S. Census Bureau}},
	month = mar,
	year = {2020}
}

@article{barrientos_providing_2018,
	title = {Providing access to confidential research data through synthesis and verification: {An} application to data on employees of the {U}.{S}. federal government},
	volume = {12},
	issn = {1932-6157},
	shorttitle = {Providing access to confidential research data through synthesis and verification},
	url = {https://projecteuclid.org/euclid.aoas/1532743488},
	doi = {10.1214/18-AOAS1194},
	abstract = {Data stewards seeking to provide access to large-scale social science data face a difficult challenge. They have to share data in ways that protect privacy and confidentiality, are informative for many analyses and purposes, and are relatively straightforward to use by data analysts. One approach suggested in the literature is that data stewards generate and release synthetic data, i.e., data simulated from statistical models, while also providing users access to a verification server that allows them to assess the quality of inferences from the synthetic data. We present an application of the synthetic data plus verification server approach to longitudinal data on employees of the U.S. federal government. As part of the application, we present a novel model for generating synthetic career trajectories, as well as strategies for generating high dimensional, longitudinal synthetic datasets. We also present novel verification algorithms for regression coefficients that satisfy differential privacy. We illustrate the integrated use of synthetic data plus verification via analysis of differentials in pay by race. The integrated system performs as intended, allowing users to explore the synthetic data for potential pay differentials and learn through verifications which findings in the synthetic data hold up and which do not. The analysis on the confidential data reveals pay differentials across races not documented in published studies.},
	language = {en},
	number = {2},
	urldate = {2020-03-12},
	journal = {The Annals of Applied Statistics},
	author = {Barrientos, Andrés F. and Bolton, Alexander and Balmat, Tom and Reiter, Jerome P. and de Figueiredo, John M. and Machanavajjhala, Ashwin and Chen, Yan and Kneifel, Charley and DeLong, Mark},
	month = jun,
	year = {2018},
	note = {tex.ids: barrientosProvidingAccessConfidential2018a
arXiv: 1705.07872},
	keywords = {Statistics - Applications},
	pages = {1124--1156}
}