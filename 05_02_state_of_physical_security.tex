\begin{center}
 DRAFT (C) Lars Vilhuber, Jim Shen - do not distribute    
\end{center}

\hypertarget{physically-protecting-sensitive-data}{%
\subsection{Physically Protecting Sensitive
Data}\label{physically-protecting-sensitive-data}}

The physical protection of sensitive data is one of the key parameters
that data custodians can and do influence. Within the Five Safes
Framework, ``safe settings'' are heavily influenced by how data are
physically protected. However, it is also the parameter that is most
dependent on current technology. While sending around floppy disks to
researchers who inserted them into desktop computers in a locked room,
isolated from computer networks, was common in the 1980s, it has been
superseded by technologies that provide similar or stronger security,
combined with greater ease of access.

Possibly because technological advances happen faster than legal or
cultural habits change, we have found that data custodians and policy
makers may not always be aware of the most current technological
possibilities when crafting the legal and contractual framework for data
access. This chapter sets out to describe the currently available
spectrum of physical protection methods. We use a framework that defines
five dimensions with which we can characterise a particular access
mechanism. We then describe several actual examples, both from the case
studies in this handbook as well as others that we are aware of.
Finally, we caution readers that by the time that this chapter is being
read, the range of possibilities may yet again have expanded (rarely
does it contract). Technological obsolescence is intrinsic to a chapter
relying so heavily on technology.

\hypertarget{five-dimensions-of-physical-security}{%
\subsubsection{Five Dimensions of Physical
Security}\label{five-dimensions-of-physical-security}}

In any data sharing setup, the fundamental setup always involves the
original holder of the data, and access by a new entity. In the context
of this Handbook, the original holder is the data custodian, and the new
accessor is the researcher. Technology determines how the physical
exchange and access may happen.

Here, we propose five dimensions of physical data security to serve as a
framework to evaluate the different defining features of various data
access mechanisms. These are:

\begin{itemize}
\tightlist
\item
  the physical \textbf{location of analysis computers and the data},
\item
  the \textbf{control over analysis computers} that researchers are
  allowed,
\item
  the \textbf{location and type of access computers},
\item
  the \textbf{level of security of access locations}, and
\item
  the \textbf{range of analysis methods available} to researchers.
\end{itemize}

When proposing and negotiating a potential use sharing agreement,
evaluating the physical security arrangements along these five
dimensions can help researchers and their data providers craft robust
mechanisms to protect data when transferring and using data for
research. Importantly, these physical access mechanisms in turn interact
with the other four safes. We highlight such interactions in the
examples provided.

For each dimension, classifications range from \textbf{1} to \textbf{3},
except for security, which has a range of \textbf{4}.

\hypertarget{location-of-analysis-computers-and-data}{%
\paragraph{Location of Analysis Computers and
Data}\label{location-of-analysis-computers-and-data}}

The researcher-accessible administrative data can be stored at one of
three types of locations. The data can remain with the data provider,
the data provider can transfer the data directly to the researcher, or
the data provider can transfer the data to a trusted third party. Each
possible data location comes with its own requirements, advantages,
disadvantages, and special considerations for the researcher and data
provider.

\begin{longtable}[]{@{}lll@{}}
\toprule
1 & 2 & 3\tabularnewline
\midrule
\endhead
Data provider & Third-party & Researcher\tabularnewline
\bottomrule
\end{longtable}

Key consideration for the choice of location is the level of trust that
the data provider has in the entity controlling the new location. The
enforcement of DUA or MOU is key. Transferring control to another entity
might be desirable when support for many researchers is a burden for the
regular business of the data provider. For instance, by transferring the
data to the researcher, a data provider may no longer be responsible for
the cost of providing computational infrastructure for data storage and
analysis. On the other hand, costs of enforcing access restrictions,
such as site visits, may be higher once physical custody of the data has
been transferred.

In certain cases, the transfer to a third party or the researcher
unlocks the possibility of combining data from multiple data providers.
For instance, government departments responsible for immigration and
taxes may not be legally allowed to share data, but they may each be
able to transfer the data to a national statistical office. Similarly,
multiple companies may not be willing (or legally allowed) to share data
with one another, but may be able to transfer the data to trusted third
party. In other situations, one branch within a government department,
responsible for enforcement, may transfer the data to another branch,
whose business it becomes to make the data accessible. The advantages of
this arrangement include having an organization that is more familiar
with and responsive to the needs of the researchers handling the data as
well as reducing the burden on staff and resources at the data provider.

Note that the location of the data on its own in no way defines how
researchers access the data, or the type of analysis a researcher can
conduct.

\hypertarget{researcher-control-over-analysis-computers}{%
\paragraph{Researcher Control over Analysis
Computers}\label{researcher-control-over-analysis-computers}}

Analysis computers are the computers on which researchers perform their
analysis on and are by definition at in the same location as the data.
They need not coincide with the computers which researchers use to
access the data. The level of control that researchers are allowed over
these computers may differ widely. In some cases, the researcher may
have physical control over the analysis computer, in others, even
software control is minimal. Of key interest to many researchers is the
software that researchers can utilize.

\begin{longtable}[]{@{}lll@{}}
\toprule
1 & 2 & 3\tabularnewline
\midrule
\endhead
Low & Medium & High\tabularnewline
\bottomrule
\end{longtable}

In the least restrictive arrangement, researchers can have full access
to the analysis computers, with no restriction on the software that
researchers can use to perform their analysis. The researcher may own
and physically control the analysis computer, such as when the data is
transferred to the researcher. Even when administrative control over the
analysis computer is retained by the data provider or a third party, the
researcher may be able to request and utilize their choice of software
on the analysis computers without much restriction.

\begin{quote}
One example of this is the way that NCES restricted-use data licenses
operate. The researcher must set up a secure data room in accordance
with NCES requirements, but is otherwise free to utilize whatever
software they want to analyze the data.
\end{quote}

In other instances, researchers only have limited control over the
analysis computers. This may occur in cases where researchers only have
remote access to the analysis computers. Limitations can range from a
white (allowed) list of software, with no restrictions on packages that
can be installed to augment that software (e.g., Stata, R, Python), to a
pre-approved list of software, which can only be modified via an
approval and security vetting process. This may be due to technical
requirements related to computer and network security, as a mechanism
for disclosure control, or the expense of acquiring or maintaining
multiple sets of software. These restrictions affect not only the base
software itself, such Stata or R, but also third party packages for
those software; while the base software itself may be unrestricted,
additional packages not signed by the original developer may not be
allowed.

\begin{quote}
The Federal Statistical Research Data Center network has a specific set
of software that they make available to researchers, who must use one of
the programs that the FSRDC has on their secure computing network.
Additions must be approved by program managers and security analysts.
\end{quote}

\begin{quote}
The Norwegian data access mechanism runs only a limited set of Python
modules, with no additions allowed.
\end{quote}

\begin{quote}
The Canadian Remote Access Mechanism runs only a limited subset of SAS
commands, with no exceptions allowed.
\end{quote}

\hypertarget{location-and-type-of-access-computers}{%
\paragraph{Location and Type of Access
Computers}\label{location-and-type-of-access-computers}}

Access computers (end points) are the computers researchers utilize to
access the data. In some cases, access computers are co-incidental with
analysis computers. However, when data are not in the same location,
access computers are distinct from analysis computers. Access computers
can be located at and be owned by the data provider, the researcher, or
a third party institution. However, ownership is not necessarily aligned
with location. For instance, a researcher may be assigned a computer
that serves both as access and analysis computer, but which is owned by
the data provider.

\begin{longtable}[]{@{}lll@{}}
\toprule
1 & 2 & 3\tabularnewline
\midrule
\endhead
Data provider & Third-party & Researcher\tabularnewline
\bottomrule
\end{longtable}

If the access computer is located at the data provider or the third
party (the \emph{data access providers}), the researcher must travel to
their location. This allows the data access providers maximum control
over the access computer and its security arrangements, including
physical monitoring, removing USB access ports, controlling user access
to specific files and folders, and other measures.

\begin{quote}
Example: Bureau of Labor Statistics Research Data Center in Washington
DC. (maybe some of the examples in Handbook)
\end{quote}

Note that when the access computer is located with the third party,
travel may still be required, but typically over shorter distances.

\begin{quote}
Example: NB. FSRDC (note that strictly speaking, FSRDC sites are under
control of the US Census Bureau, but are located on university campuses
or within other research institutions)
\end{quote}

Access computers can be of several types. In some cases, the agreement
may prescribe certain types of access computers, in others, they may
remain undefined. When not further defined, a researcher may be able to
use any computer for access, for instance, when access is via a secure
website. VDI access, defined below, may be allowed from any computer
capable of running the necessary software, including tablets. On the
other hand, secure laptops with dedicated VPN setups and encrypted
hard-drives may be deployed. In certain cases, dedicated thin clients,
including zero-footprint thin clients, provide similar functionality as
such dedicated laptops, without the computational capability that such
laptops may have. As the enumeration of possibilities also makes clear:
physical configuration control for such access computers may also differ
widely. We discuss software configuration control below.

\hypertarget{security-of-access-locations}{%
\paragraph{Security of Access
Locations}\label{security-of-access-locations}}

The location of access can have varying levels of security. We classify
the levels of security into four levels, ranging from \textbf{open
access} (no security) to \textbf{low, medium, and high} security
arrangements. Unlike the other dimensions outlined above, these are not
concrete distinctions between different mechanisms but rather broad
classifications of the overall rigor of physical security regimes. Note
that in some instances, specific rooms may be mandated, whereas the open
access regime might not specify any specific location.

\begin{longtable}[]{@{}llll@{}}
\toprule
1 & 2 & 3 & 4\tabularnewline
\midrule
\endhead
High & Medium & Low & Open\tabularnewline
\bottomrule
\end{longtable}

An \textbf{open access} arrangement is one where there are no mandated
controls on the physical location of the access computer. The access
computer is protected only by hardware and software configuration of the
device itself. This is typically seen in remote submission systems, such
as the IAB JoSuA interface where there are no explicit restrictions on
where the researcher can use the interface. Trivially, this may be true
when access and analysis compture are coincident with the researcher's
laptop.

\begin{quote}
Example: Access to IAB's Joshua can be from any internet connected
computer, regardless of location.
\end{quote}

A \textbf{low security} arrangement has a mandated location for the
access room or other basic security precautions, but otherwise has no
access controls outside of the control of the researcher. Frequently
this takes the form of provisions in the data use agreement between the
data provider and researcher mandating certain steps such as storing the
data in a locked room, but the security arrangements are maintained by
the researcher. In some cases, the data provider explicitly reserves the
right to approve the security arrangements, conduct audits, or otherwise
directly verify that the researcher is in compliance with the security
requirements or the access room.

\begin{quote}
French CASD mandates that thin clients be deployed in university
offices, although relaxations were allowed during the 2020 COVID-19
worldwide health crisis. (CITATION)
\end{quote}

\begin{quote}
The SFUSD-Stanford data use agreement template mandates that Stanford
researchers take ``reasonable and appropriate efforts'' to keep the data
``in a space otherwise physically and electronically secure from
unauthorized access''. However, the district does not exercise physical
control over the researchers' access room security.
\end{quote}

\begin{quote}
The requirements for the data location outlined in the NCES
restricted-use data license is an example of a medium security
arrangement under the control of the researcher. The data must be kept
in a locked room with access restricted only to licensed researchers,
with the security arrangements subject to random audits by NCES.
\end{quote}

An access room with a \textbf{medium security} setup has mandated
security features. Access is restricted to approved researchers, with a
minimum of a physically secured facility such as a locked room where
only approved researchers have key or keycard access. Frequently, medium
security room setups will be under the control of a third party or the
data provider itself. This enables the room administrator to directly
monitor who has access to the room and the physical security of the
access computers within the room.

\begin{quote}
Example are the IAB thin clients in various locations, including in
North America. These are in a room under the control of the research
institution hosting the thin client, and are not freely accessible to
the researcher.
\end{quote}

A \textbf{high security} access room has stronger specifications for
physical security. This can include mandating that the room have secured
walls that fully extend from the floor to ceiling with no gaps,
electronic shielding for the room, video monitoring of the room,
identity or biometric verification for people entering the room, and
other security arrangements that extend beyond simple access controls
for people entering the room. The NB-IRDT data centers, with their
stringent access controls and additional physical safeguards such as
bolting the server to the floor in a separate locked cage, falls into
the high security category.

\hypertarget{analysis-methods}{%
\paragraph{Analysis Methods}\label{analysis-methods}}

The range of analysis methods allowed by access systems can vary widely.
Researchers may be able to leverage a wide range of analysis methods,
ranging from simple tabulations to complex machine learning tasks. In
other cases, they may be limited to a small set of methods, defined by
the data custodian for technical or security reasons. Note that this
dimension is distinct from the control that researchers have over
software installation. A system may allow for any analysis method, as
long as it is implemented in SAS - a situation where the software
choices may be limited (and limiting for researchers), but where the
analysis methods are nearly unrestricted.

\begin{longtable}[]{@{}lll@{}}
\toprule
1 & 2 & 3\tabularnewline
\midrule
\endhead
Restrictive & Medium & Flexible\tabularnewline
\bottomrule
\end{longtable}

Environments with unrestricted analysis methods allow researchers to
utilize the full range of methods available in the set of software that
is available on the analysis computer, subject to other restrictions on
the analysis computer as discussed in the previous section. Limited
analysis methods place restrictions on what researchers can do, such as
limiting the language set available to researchers to a whitelisted set
of commands or utilizing online tabulators that limit the researcher to
using conditional tables.

\begin{quote}
Norwegian system is limited both to Python, and within Python, to a
limited set of analysis methods, a strict subset of the Pandas package.
\end{quote}

\begin{quote}
IAB system only allows for Stata in Josua, but within Stata, few
restrictions are imposed.
\end{quote}

\hypertarget{technical-features-infrastructure-implementations}{%
\subsubsection{Technical features, infrastructure,
implementations}\label{technical-features-infrastructure-implementations}}

\hypertarget{remote-desktop}{%
\paragraph{Remote desktop}\label{remote-desktop}}

Remote desktop systems (also referred to as Virtual Desktop
Infrastructure, VDI) are software packages that enable users on one
computer to connect to another computer over a network. This allows a
researcher to use an analysis computer remotely, with the desktop
environment of the analysis computer displayed on the client device, the
access computer. This enables the data holder to retain full physical
control over the analysis computer, which can be configured to prevent
file transfers to the researcher's computer, prevent the researcher from
installing software, and other controls. All modern Microsoft operating
systems have had native remote desktop clients, and there are many
implementations for other operating systems as well.

\hypertarget{thin-clients}{%
\paragraph{Thin Clients}\label{thin-clients}}

Thin clients are computers that have been optimized for utilizing remote
desktop software to connect to a server. Very restrictive
implementations of thin clients can prohibit any usage beyond displaying
information from the server and accepting mouse and keyboard input from
the user. One of the main advantages of dedicated hardware thin clients
is that they are cheaper and simpler than regular computers. As of the
time of writing, thin clients can cost as little as \$100 for the
hardware itself, in contrast with the cheapest entry level computers
which are several hundred dollars. Note however that most thin clients
require a server-side infrastructure to support both access and security
updates. Thin clients typically operate without local storage, thus
preventing users from saving data to the client.

For data providers and researchers setting up remote access to analysis
computers via thin clients, the clients themselves do not need to be
capable of running statistical software or intensive analysis; the
analysis will occur on the server that hosts the data and software
packages. Thin clients can either be provided directly to researchers or
be housed within a research data center. Thin clients can be sourced
from many manufacturers of enterprise hardware, both as standalone
devices for the user to configure as well as full fledged hardware and
software package solutions configured by the vendor.

\begin{quote}
IMAGE of CASD thin client
\end{quote}

\begin{quote}
IMAGE of a commercial zero-footprint thin client
\end{quote}

\hypertarget{biometric-authentication-fingerprint-etc}{%
\paragraph{Biometric authentication (fingerprint,
etc)}\label{biometric-authentication-fingerprint-etc}}

Biometrics are physical and biological features unique to individuals.
Biometric authentication is the use of biometric features to verify the
identity of individual users. By verifying the user's identity based on
stored information about authorized users, biometrics can be used to
authenticate authorized access to access computers, analysis computers,
and access rooms. The main components of such an access system includes
the biometric sensor itself, which is connected to a database that
contains the set of validated users, and controls either the physical or
electronic lockouts for a given system (e.g.~entering a room or logging
into a computer).

Most biometric authentication techniques rely on the physical
characteristics of individuals. One of the most common biometric
technologies in current use is fingerprint scanners for consumer
electronics such as laptops and smartphones. Other commonly used
technologies include facial recognition, retinal or iris recognition,
and voice identification. Biometric authentication techniques can serve
both as a primary form of identification as well as being layered in two
or multiple factor authentication techniques, such as in conjunction
with passwords or other devices. When applied to physical data security,
biometrics authentication can be required by data providers as part of
an access agreement, collected from authorized users, and implemented by
any of the parties with administrative control over access rooms, access
computers, and analysis computers as required.

\hypertarget{physical-access-cards}{%
\paragraph{Physical access cards}\label{physical-access-cards}}

Physical access cards are electronic cards that identify the card bearer
for a physical access control system. Access to devices or rooms are
secured by a card reader validates the user's card with a central
database that has a set of valid cards and subsequently disables the
locks on the system or room that it is protecting. The cards themselves
can use magnetic stripes, barcodes, electronic fields, or other systems
for interfacing with the card reader. Physical access cards are commonly
used in universities and have the advantage of likely having existing
infrastructure to support the creation of secure access rooms for
researchers receiving administrative data.

\hypertarget{secure-rooms}{%
\paragraph{Secure Rooms}\label{secure-rooms}}

Beyond access control, rooms can have various specifications for
securing it against unauthorized access. For some secure rooms that
house administrative data for research purposes, one requirement is
having the room fully enclosed by walls that extend from floor to floor
with a minimum number of possible entryways to minimize the possibility
of unauthorized access. Any doors, windows, air vents, and other
possible entryways would be secured by bars, mesh, or other methods to
deter access. The doors and walls can have minimum specifications of
construction materials, techniques, and thickness to increase protection
against physical attacks; reinforced doors and walls offer increased
protection compared to regular home and office construction materials.
Door hinges, access panels, partitions, windows, and other possible ways
of entering the room would be installed from the inside of the secure
room to prevent their removal from the outside. In instances where the
room stores data itself, the devices within the room can be mandated to
have no outside network connections (an air-gapped network), or no
network connection at all

\hypertarget{ip-address-restrictions}{%
\paragraph{IP address restrictions}\label{ip-address-restrictions}}

For remote access mechanisms, one way to ensure that only an authorized
user has access to the remote system is to restrict the
\textbar{}\textbar{}IP\textbar{}\textbar{} address of the devices that
are allowed to connect to the server. There are two types of
restrictions, blacklisting and whitelisting. Blacklisting specific
addresses is used to block known or potential bad actors but otherwise
does not restrict connections to the server; whitelisting only
authorized users is the primary use of IP restrictions in an access
control mechanism. This is frequently an option built into the software
for managing the server. For example, software used for managing secure
file transfer protocols can restrict the IP addresses that it will
accept connections from. For data providers and researchers, this can be
restricted to specific devices that the researcher registers with the
data provider as the access computer.

\hypertarget{vpn}{%
\paragraph{VPN}\label{vpn}}

Virtual private networks (VPN's) are used to allow users to exchange
data over public networks as if they were directly connected on a
private network. VPNs utilize an encrypted channel established between
the remote computer and the network to securely transfer data and gain
access to resources on the network. Users must authenticate themselves,
such as with usernames and passwords, to access the VPN. VPN's has
applications for transferring data to researchers as well as remotely
accessing data by either the researcher themselves or from a remote data
center. For open access settings VPNs can be particularly useful, as
they allow the encryption (and therefore security) of any data that the
researcher can access from a public network.

\hypertarget{on-site-storage}{%
\paragraph{On-site storage}\label{on-site-storage}}

The proper storage of research data is an important issue for data
holders to consider. Reliability and security are the two main
considerations for on-site storage of data. The reliability of the
storage refers both to preventing data loss as well as system uptime.
Data loss can be mitigated by using multiple disks in a mirrored array
such that the failure of any one (or multiple) disks does not result in
the loss of data as well as utilizing robust backup strategies tailored
to the risk tolerance as well as any legal or data use agreement
requirements. Maximizing system uptime is important to allow for the
uninterrupted use of data for research. Specialized storage servers
allow for maintenance, including hot-swapping storage drives, while the
server remains available for use.

Security in the context of setting up data storage is the prevention of
unauthorized access to the data. On top of access controls for users,
the storage device itself needs to be properly configured and kept up to
date with security patches. Full disk encryption for the storage device,
where the entire hard drive is encrypted and needs to be unlocked before
using it, helps secure the device in the event an adversary attempts to
gain access to the device. The encryption of the data itself can provide
the final line of defense in the event that an adversary does get access
to the storage device.

\hypertarget{data-access-controls}{%
\paragraph{Data access controls}\label{data-access-controls}}

Access control regulates what users can view or use in a computing
environment. This is of particular relevance for systems where multiple
researchers utilize the same computing resources for access or analysis
to data. Setting user permissions on directories at the operating system
level on the analysis computer is one method of implementing access
controls by preventing researcher accounts from accessing data that they
are not authorized to. Another method is to use a virtual machine that
is a completely isolated computing environment running on a host
computer; a host computer can run multiple virtual machines, with each
researcher or research project having a specific virtual machine to
preven the sharing of data between projects.

\begin{quote}
{[}Lars to add other techniques{]}
\end{quote}

\hypertarget{transfer-mechanisms}{%
\paragraph{Transfer mechanisms}\label{transfer-mechanisms}}

The transfer of data between data providers, third parties, and
researchers occurs in many data sharing partnerships. Data can be
transferred through various network protocols, cloud services, or a
physical medium that is exchanged between the various parties. There are
many network protocols used for transferring data, of which many
transfer data without encryption and are therefore vulnerable to being
read in transfer. One out of the box solution for secure file transfers
is the SSH File Transfer Protocol (SFTP), which encrypts the data sent
between the client and server. Cloud storage services such as Google
Drive, Dropbox, Box, Microsoft OneDrive, and others, also support the
encrypted transfer and storage of data. However, utilizing cloud storage
services requires placing the data under the control of a third party,
which may be prohibited depending on the data sharing agreement. In
circumstances where network or cloud services cannot be used, the
transfer of fully encrypted physical mediums such as CD-ROMs or hard
drives through couriers is another transfer mechanism that can be
utilized. The password must never be sent with the medium itself.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\hypertarget{typical-access-mechanisms}{%
\subsubsection{Typical access
mechanisms}\label{typical-access-mechanisms}}

\hypertarget{remote-execution}{%
\paragraph{Remote Execution}\label{remote-execution}}

Under a remote execution model, data is stored remotely in a location
such that a researcher does not have direct access to the data. In this
scenario, a researcher needs to submit a request to have the data
provider run the analysis on behalf of the researcher and share only the
summary output, with the researcher never having access to the actual
data.

Remote execution requires that a data provider maintain dedicated staff
with the technical expertise to interface with researchers, run the
researchers' analysis, and check the output for data anonymity before
sending it back to the researchers. The systems to perform the analysis
and disclosure checks can be manual or automatic, which both require
technical experts to maintain.

The data provider also needs to create and maintain the systems to
facilitate the transfer of the necessary files (researchers need to
receive the synthetic data, submit analysis files, and receive the
output) as well as to allow the data provider to run the necessary
analysis on behalf of the researcher.

A key requirement for such a system is the provision of accurate
codebooks and documentation from data providers to researchers such that
they can prepare the appropriate data request and analysis files for the
data provider. While important for all data exchanges, this is
especially important for remote execution since researchers cannot
personally examine the data. One common method is for the data provider
to give researchers synthetic data files that have the same variables
and table structures as the real data, but have fictitious values for
the variables.

By maintaining full control of the data as well as having the
opportunity to check the researchers' request and check the output
before handing it back to the researcher, remote execution gives the
data provider the highest level of data security. The primary tradeoff
is the additional resources required on the part of the data provider to
perform these tasks and the additional time it will take for a
government to receive relevant results from their research partner.

One example of a national statistical agency that uses a remote
execution model is Statistics Canada, which allows researchers to submit
analysis code after testing it on synthetic data for a select number of
their databases. The Statistics Canada implementation follows the
standard remote execution model. Similarly, the German IAB has a remote
execution portal where researchers can test their code on test data data
and upload their code for execution, and only access approved results
when their job is complete.

A variant on the remote execution model is the United States National
Center for Health Statistics Research Data Centers, which requires
researchers to first submit their analysis code for manual approval
before arriving at the research data center itself to run the analysis.

\hypertarget{physical-data-enclave}{%
\paragraph{Physical Data Enclave}\label{physical-data-enclave}}

In a physical data enclave, researchers must physically enter the data
enclave to access the data and run their analysis code. The data
provider can choose to store the data either on site at the data enclave
itself, or store the data on a remote server that can only be accessed
by specifically configured computers located within the data enclave. In
either case researchers only have access to the data in a secure and
physically controlled environment.

To run a physical data enclave, a data provider needs to have an
access-controlled space for researchers to work in with the requisite
servers, computers, and software packages. The data provider must also
have staff or automated systems to ensure that researchers are not
running proscribed analyses and checking the outputs before being
removed from the physical data enclave.

The data provider gets most of the security benefits of remote execution
by maintaining full control over the data in the entire research
process. It removes the potential bottleneck and additional expense of
requiring dedicated staff on the part of the data provider to actually
run the analysis on behalf of the researcher. The ability of researchers
to personally examine the data in controlled settings enables them to
potentially work with data providers on improving data quality in such a
setting.

However, physical data enclaves still impose restrictions on the
flexibility of researchers and the speed at which governments can
receive research findings; instead of waiting for someone to run the
remote execution for them, researchers have to schedule visits to a
physical location. It also requires the data provider to provide the
physical and technical infrastructure for researchers to conduct their
research in a secure location.

Different models of physical data enclaves exist. The traditional model
in the United States is the Federal Statistical Research Data Center
(FSRDC) network, where federal statistical agencies partner with
research institutions to provide secure data access facilities managed
by the US Census Bureau. Research institutions maintain the data enclave
itself and the client computers within the data enclaves, which are
connected to servers maintained by statistical agencies. Researchers
must be approved by the Census Bureau and pass background checks before
gaining access to the facility and data, and the output is subject to
disclosure-avoidance review by FSRDC staff. FSRDC type facilities
represent the highest level of security for protecting sensitive data,
but are also more expensive than other methods which rely more on trust
and less on physical security. Initial startup costs could reach
hundreds of thousands to millions of dollars, and ongoing operating
costs, while much lower, must cover full time staff and maintenance on
the equipment.

An innovation on the physical data enclave is the SafePod network in the
United Kingdom, which scales down a full-scale research data center. The
SafePod has much lower installation costs than a full data center,
around £25,000. It is a standardized, prefabricated unit that can be
placed in any partner institution, and the pod itself serves as the
physically controlled space. Like a FSRDC, a SafePod facilitates
researcher access to data stored on statistical agency servers; in this
case, with access to the data approved by the actual data providers
while the partner institution handles local support and physical access
controls. While the SafePod is still a physical location that requires
installation and ongoing staff and maintenance, it is an example of
innovation in physical data enclaves that makes this highest level of
data security less costly.

\hypertarget{virtual-data-enclave}{%
\paragraph{Virtual Data Enclave}\label{virtual-data-enclave}}

A virtual data enclave is conceptually similar to physical data
enclaves, except there is no physically controlled space that the
researcher must visit in order to access the data. Rather, researchers
utilize different technical means to remotely access servers that store
data and perform their analysis on the remote server. Software access
controls perform automated scans of the output and prevent the
researcher from removing data from the remote server.

Data providers using a virtual data enclave model maintain the servers
that house the data and enable researchers to run their analysis, the
connections with the thin clients and the remote desktops used to
connect with the server. A virtual data enclave includes trained staff,
who help process data and assist researchers. There are two basic
approaches to the remote access mechanism: either using remote desktop
software that the researcher can install on their own computer, or a
dedicated computer (referred to as thin clients) that the data provider
loans the researcher to connect to the server. To address physical
security concerns, data providers can impose storage and safety
requirements on researchers as part of the agreement that allows them
access to the virtual data enclave or have dedicated staff conduct
periodic audits.

The virtual data enclave model has a major advantage for researchers in
that they no longer have to travel to specific facilities to perform
their research. Furthermore, instead of the cost of maintaining an
entire physical data enclave and the associated staff at each enclave,
the data provider only needs to provide researchers with the necessary
thin clients or remote desktop systems and can centralize their data
staff.

The primary tradeoff is the slightly lower level of data security when
the researcher accesses the data, as the data provider relies on only
software level controls without the ability to physically check the
researcher and their output as in a physical data enclave. However, with
the proper implementation this level of security is still quite robust
and less costly.

Statistics Denmark is one major statistical agency that uses a virtual
data enclave model for access to their data. Researchers approved by
Statistics Denmark can utilize specific client software for remote
access to servers that house research data and perform their analysis
through the client software. Researchers must sign agreements with
Statistics Denmark with specific requirements to protect the physical
security of the terminal that they use to access the server, consent to
having their transactions on the server logged to prevent unauthorized
copying of data, and ensure that they do not identify individual persons
or enterprises in their output.

\hypertarget{researcher-provided-infrastructure}{%
\paragraph{Researcher-Provided
Infrastructure}\label{researcher-provided-infrastructure}}

In some data sharing arrangements, the data provider has the researcher
provide the data storage, access, and analysis infrastructure. The data
provider will provide the data to the researcher, who has custodianship
over the data.

Data providers must ensure that they properly remove variables
containing personally identifying information from data that they
transfer to researchers in order to protect the privacy of study
participants. In the instance that researchers have access to
potentially identifiable data, the data provider must take care to
ensure that the results produced for publication do not contain
personally identifiable information. The data provider and researcher
must have the technical means to securely transfer the data. Many such
tools exist, including commercial enterprise level cloud services such
as Google Drive, Box, and Dropbox that can be configured for secure data
storage and transfer.

This process allows researchers significantly more flexibility and rapid
turnarounds on research findings of importance to their government
partners. Allowing researchers to store the data on their own devices
may reduce the burden on data providers, who only have to provide the
data itself and the staff necessary to transfer it to the researchers.
On the other hand, data providers may also choose to conduct random on
site inspections or have researchers submit their output for approval,
which requires staff time. In instances where researchers can work very
closely with the data providers' technical staff with direct access to
their data, they can also help the government learn more about their
data and improve processes and systems at the government.

Many research projects and data providers utilize data transfers to
researchers, particularly among smaller scale data providers for whom a
more expensive data enclave model is less feasible. For example, San
Francisco Unified School District has a long-standing partnership with
Stanford University, where the Center for Education Policy Analysis
(CEPA) at Stanford acts as a data warehouse for individual-level
administrative data on behalf of the district. While many of the
researchers who use the data are affiliated with CEPA, the CEPA has
dedicated staff with no ties to specific research projects to manage the
warehouse. The district approves researchers and projects to have access
to the data, while the warehouse performs data cleaning, anonymization,
and ultimately provides data files to the researcher.

Large scale implementations of the data transfer model for sensitive,
individual-level data also exist. The U.S. National Center for Education
Statistics maintains a restricted-use data license model that requires
researchers to set up their own version of a physical enclave, at their
home location, as a requirement for becoming a license holder. The
researcher must maintain an access-controlled secure data room with
specific physical and electronic protection requirements and must
undergo random NCES audits to ensure compliance with these procedures.
The data is transferred to the researcher via encrypted disks with the
passwords sent separately, such that the data is protected in transit
and only the researcher with both the data disk and password can access
the data. Combining the efficiency of data transfer with the increased
security of physical and electronic protection shows how data access can
be tailored for individual circumstances based on sensitivity and cost
needs.

\hypertarget{examples-from-the-handbook-along-the-five-metrics}{%
\subsubsection{Examples from the handbook along the five
metrics}\label{examples-from-the-handbook-along-the-five-metrics}}

In this section, we explore how the five dimensions map onto the case
study chapters in the handbook. Each set of data providers and
researchers utilizes a unique combination of the five metrics for their
data sharing framework.

\hypertarget{san-francisco-unified-school-district-sfusd-stanford-partnership}{%
\paragraph{San Francisco Unified School District (SFUSD)-Stanford
Partnership}\label{san-francisco-unified-school-district-sfusd-stanford-partnership}}

```\{r, echo=FALSE, fig.width=4, fig.height=2\} sfusd =
data.frame(metrics=c(``Data Location'',``Analysis Computer'',``Access
Computer'',``Access Room'',``Analysis Method''), rank=c(3,3,3,3,3))
plot(data=sfusd)

``` In the SFUSD-Stanford Partnership, SFUSD uses the CEPA Data
Warehouse as a trusted data service that ultimately transfers a
restricted set of data to the researcher. The location of the analysis
computers and the data are therefore at the researcher, and the access
computer is the same as the analysis computer. Computers used to hold
and analyze SFUSD data are subject to Stanford and SFUSD requirements
for data security, including enterprise operating system management and
whole disk encryption for any device that holds the data. The
researchers otherwise have a high degree of control over the analysis
computer. The access rooms are low security; researchers must take
reasonable measures to physically protect the data but there are no
specific requirements or checks on the location of the data itself.
Typically this takes the form of storing the researcher's computer in a
locked office, although in the case of graduate student researchers the
offices may be shared. The analysis methods are unrestricted, with
researchers being able to use any set of statistical software that they
can acquire for analysis.

\hypertarget{nb-institute-for-research-data-and-training-nb-irdt}{%
\paragraph{NB Institute for Research, Data and Training
(NB-IRDT)}\label{nb-institute-for-research-data-and-training-nb-irdt}}

\texttt{\{r,\ echo=FALSE,\ fig.width=4,\ fig.height=2\}\ nbirdt\ =\ data.frame(metrics=c("Data\ Location","Analysis\ Computer","Access\ Computer","Access\ Room","Analysis\ Method"),\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ rank=c(2,2,1,1,2))\ plot(data=nbirdt)}

The NB-IRDT serves as a third-party data center for the various data
providers that supply it with data to make available to researchers. The
data location, access computers, and analysis computers are all located
on site at NB-IRDT facilities. Researchers use workstations to remotely
access data from a central server, and store their data on a local
server at the specific facility that the researcher is at. Researchers
have partial access to analysis computers, without the ability to
Researchers have limited access to the access computer, with stringent
security requirements placed upon their usage of the research
workstation. The access room is under high security, with strong
specifications of security such as restricting mobile devices and
outside materials, physical controls on the servers and workstations,
and having dedicated fiber optics cables to handle data connections
between the central and satellite locations. {[}Missing information
about access computer software and analysis methods from chapter{]}

\hypertarget{institute-for-employment-research-iab}{%
\paragraph{Institute for Employment Research
(IAB)}\label{institute-for-employment-research-iab}}

\texttt{\{r,\ echo=FALSE,\ fig.width=4,\ fig.height=2\}\ iab1\ =\ data.frame(metrics=c("Data\ Location","Analysis\ Computer","Access\ Computer","Access\ Room","Analysis\ Method"),\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ rank=c(2,2,1,1,2))\ plot(data=iab1)}

The IAB uses three different access models, each with its unique
implementation of the five metrics of data security. The most
restrictive access method is the IAB on-site access method, where
researchers must go to an affiliated research data center. In this
model, the data location and analysis computers are both located at the
IAB, which acts as a third party for the German Federal Employment
Agency. Researchers have restricted access to the analysis computers,
including not being allowed to install their own software. The access
computers are located at RDC's under the control of the IAB itself or
third-party partner institutions, consisting of secured workstations at
RDC-IAB and thin clients at its partner institutions. The analysis
methods are limited to the statistical software packages available at
the specific RDC. The room security depends on the specific RDC,
although all RDC's generally have strong physical specifications for
security with additional restrictions beyond just access controls
managed by the RDC administrator.

\texttt{\{r,\ echo=FALSE,\ fig.width=4,\ fig.height=2\}\ iab2\ =\ data.frame(metrics=c("Data\ Location","Analysis\ Computer","Access\ Computer","Access\ Room","Analysis\ Method"),\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ rank=c(2,3,1,4,2))\ plot(data=iab2)}

For IAB remote execution, the data location and analysis computers are
both still under the control of the IAB. Analysis methods are limited to
preparing program code on test data to run on the analysis computers at
the IAB. However, the access computer is the researcher's own device
utilizing the JoSuA portal to submit requests to the IAB. The access
room is open with no security requirements, as the researchers are
limited to the deidentified output from the JoSuA system.

\texttt{\{r,\ echo=FALSE,\ fig.width=4,\ fig.height=2\}\ iab3\ =\ data.frame(metrics=c("Data\ Location","Analysis\ Computer","Access\ Computer","Access\ Room","Analysis\ Method"),\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ rank=c(3,3,3,2,3))\ plot(data=iab3)}

The IAB also makes anonymized data products available for direct
download by researchers. In this instance, the data location, acces, and
analysis computers are at the researcher's institution, with researchers
having full administrative control over the computer systems. As a
result of that, they have the full range of analysis methods available
as well. The IAB data use agreement for downloading the scientific use
files specifics medium security requirements, with the building and room
required to have some level of access control or monitoring against
unauthorized access; options range from receptionists and security
guards to admission simple key locks. There are additional requirements
for electronic security such as encrypting the computers and servers
with access to the data.

\hypertarget{ohio-longitudinal-data-archive-olda}{%
\paragraph{Ohio Longitudinal Data Archive
(OLDA)}\label{ohio-longitudinal-data-archive-olda}}

\texttt{\{r,\ echo=FALSE,\ fig.width=4,\ fig.height=2\}\ olda\ =\ data.frame(metrics=c("Data\ Location","Analysis\ Computer","Access\ Computer","Access\ Room","Analysis\ Method"),\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ rank=c(3,3,3,3,3))\ plot(data=olda)}

The Ohio Longitudinal Data Archive is a third party organization that
provides data to researchers on behalf of the government. The data is
initially located at the third party institution before ultimately being
transferred to researchers via a secure FTP server. The researchers have
full control over the analysis and access computer, which is required to
be a desktop computer located in the researcher's office space. This is
a low specification of access room security, placing no additional
requirements beyond utilizing a specific space. Researchers have full
analysis methods available for them. Data can be provided in a variety
of formats, including CSV files that enable the researcher to use any
analysis software or method of their choosing.

\hypertarget{aurora-healthcare}{%
\paragraph{Aurora Healthcare}\label{aurora-healthcare}}

The researchers for this project received data from the data provider
via a secure file transfer protocol. The data location, acces computer,
and analysis computers were all located at the researcher's home
institution. {[}need more info from Amy and Laura{]}

\hypertarget{cape-town}{%
\paragraph{Cape Town}\label{cape-town}}

In the Cape Town partnership, the data was transferred from the data
provider to the researcher. As such, the data location, access, and
analysis computers are all with the researcher, with the researcher
having a full range of analysis methods available. {[}need more
information about access rooms, some more detail about how they did the
transfer and storage etc{]}

\hypertarget{other-examples-along-the-five-metrics}{%
\subsubsection{Other examples along the five
metrics}\label{other-examples-along-the-five-metrics}}

\hypertarget{fsrdc}{%
\paragraph{FSRDC}\label{fsrdc}}

\hypertarget{safepod}{%
\paragraph{Safepod}\label{safepod}}

\hypertarget{french}{%
\paragraph{French}\label{french}}

\hypertarget{national-center-for-education-statistics-nces-restricted-use-data-license}{%
\paragraph{National Center for Education Statistics (NCES) Restricted
Use Data
License}\label{national-center-for-education-statistics-nces-restricted-use-data-license}}

\texttt{\{r,\ echo=FALSE,\ fig.width=4,\ fig.height=2\}\ nces\ =\ data.frame(metrics=c("Data\ Location","Analysis\ Computer","Access\ Computer","Access\ Room","Analysis\ Method"),\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ rank=c(3,3,3,2,3))\ plot(data=nces)}

The NCES, a part of the United States Department of Education, allows
researchers to apply for a restricted use data license to store data on
site at the researcher. The data location, access computer, and analysis
computers are all under the control of the researcher, with specific
security requirements for the computers, the storage mediums that
researchers receive the data on, and any physical documentation. With
full administrative control of the analysis computers, researchers also
have no restrictions on the analysis methods that they are allowed to
use. NCES mandates a medium level of security for the access room,
requiring that it must be a locked room with access restricted to
authorized users but without additional specifications for security. The
security arrangements must be approved by NCES prior to the receipt of
restricted use data and are subject to unannounced inspections.

\hypertarget{bureau-of-labor-statistics-bls-onsite-access}{%
\paragraph{Bureau of Labor Statistics (BLS) Onsite
Access}\label{bureau-of-labor-statistics-bls-onsite-access}}

\texttt{\{r,\ echo=FALSE,\ fig.width=4,\ fig.height=2\}\ bls\ =\ data.frame(metrics=c("Data\ Location","Analysis\ Computer","Access\ Computer","Access\ Room","Analysis\ Method"),\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ rank=c(1,1,1,1,2))\ plot(data=bls)}

The BLS has two research data centers in its national office at
Washington D.C. for access to particularly sensitive research files and
surveys that are not available offsite or through the FSRDC network. The
data location, access computers, and analysis computers are all located
and controlled by BLS. As with other research data centers, there is a
high specification of security for the access room, with access limited
to approved researchers and all materials subject to search when
entering or exiting the facility. Analysis methods are restricted to
pre-installed versions of SAS, Stata, and SPSS, with limited use of
approved statistical software and data files that can be installed by
the BLS staff.

\hypertarget{nchs}{%
\paragraph{NCHS}\label{nchs}}

{[}https://www.cdc.gov/rdc/b2accessmod/ACs200.htm - remote access no
longer available, otherwise available at NCHS RDC or FSRDCs, not sure
about the utility of ``yet another RDC'' example{]}
